---
title: "Knn_Classification"
author: "Osama Bin Zahir"
date: "`r Sys.Date()`"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#Importing required packages

```{r}
library(psych)
library(FNN)
library(ISLR)
library(class)
library(caret)
library(caTools)
```

#Importing dataset

```{r}
universalbank <- read.csv("C:\\Users\\Osama Zahir\\Downloads\\UniversalBank.csv")
summary(universalbank)
```
#Eliminating ZIP code and ID from the dataset

```{r}
ds=subset(universalbank, select=-c(ID, ZIP.Code ))
summary(ds)
```
#converting education into factor

```{r}
ds$Education = as.factor(ds$Education)
```

#convert education to dummy variables

```{r}
groups = dummyVars(~.,data = ds) #this creates dummy groups
ds_df = as.data.frame(predict(groups, ds))
summary(ds_df)
```

#partitioning the data into training and validation

```{r}
set.seed(123)
split = sample.split(ds_df, SplitRatio = 0.6)
train.df = subset(ds_df, split == TRUE)
valid.df = subset(ds_df, split == FALSE)

# Print the sizes of the training and validation sets
print(paste("The size of the training set is:", nrow(train.df)))
print(paste("The size of the Validation set is:", nrow(valid.df)))
```

# normalizing the data

```{r}
train.norm.df = train.df[,-10] #note that personal income is the 10th variable
valid.norm.df = valid.df[,-10]

norm.values = preProcess(train.df[,-10], method=c("center", "scale"))
train.norm.df = predict(norm.values, train.df[,-10])
Valid.norm.df = predict(norm.values, valid.df[,-10])
```

#Question 1:

```{r}
new_cust = data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  `Securities.Account` = 0, 
  CD.Account = 0,            
  Online = 1,
  `CreditCard` = 1          
)
new_cust
```

# Normalize the new_cust

```{r}
new.cust.norm = new_cust
new.cust.norm = predict(norm.values, new.cust.norm)
```

```{r}
knn1 = class::knn(train = train.norm.df, test = new.cust.norm, cl = train.df$Personal.Loan, k = 1)
knn1
```

#Based on the kNN algorithm with a k value of 1 (i.e., considering only the nearest neighbor), the algorithm predicts that the new customer is in the class labeled "0." which means loan is not accpeted.

# Question 2

```{r}
accuracy.diff <- data.frame(k = seq(1, 15, 1), overallaccuracy = rep(0, 15))
for(i in 1:15) {
  KNN.Pred <- class::knn(train = train.norm.df, 
                         test = Valid.norm.df, 
                         cl = train.df$Personal.Loan, k = i)
  accuracy.diff[i, 2] <- confusionMatrix(KNN.Pred,   
                                    as.factor(valid.df$Personal.Loan),positive = "1")$overall[1]
}

which(accuracy.diff[,2] == max(accuracy.diff[,2])) 

plot(accuracy.diff$k,accuracy.diff$overallaccuracy)

```

# The best K is 3

# Question 3

```{r}
# Best k value 
best_k <- 3

# Train the kNN model with the best k
best_knn <- class::knn(train = train.norm.df, 
                        test = Valid.norm.df, 
                        cl = train.df$Personal.Loan, k = best_k)

# Create the confusion matrix
confusion_matrix <- confusionMatrix(best_knn, as.factor(valid.df$Personal.Loan))

# Display the confusion matrix
print("Confusion Matrix:")
print(confusion_matrix)
```

#Question 4:

```{r}
# Customer data
new_cust <- data.frame(
  Age = 40,
  Experience = 10,
  Income = 84,
  Family = 2,
  CCAvg = 2,
  Education.1 = 0,
  Education.2 = 1,
  Education.3 = 0,
  Mortgage = 0,
  `Securities.Account` = 0, 
  CD.Account = 0,            
  Online = 1,
  `CreditCard` = 1          
)

# Normalize the customer data
new_cust.norm <- predict(norm.values, new_cust)

# Classify the customer using the best k (k = 3)
customer_classification <- class::knn(train = train.norm.df, 
                                      test = new_cust.norm, 
                                      cl = train.df$Personal.Loan, 
                                      k = best_k)

# Display the classification result
if (customer_classification == 1) {
  cat("The customer is classified as 'Accepted (1)' for a personal loan.\n")
} else {
  cat("The customer is classified as 'Not Accepted (0)' for a personal loan.\n")
}
```

# Question 5

```{r}
# Partition the data into training, validation, and test sets (50% : 30% : 20%)
set.seed(123)
split1 <- sample.split(ds_df, SplitRatio = 0.5)
train_valid.df <- subset(ds_df, split1 == TRUE)
valid_test.df <- subset(ds_df, split1 == FALSE)

# Further split the combined validation and test data into 30% validation and 20% test
split2 <- sample.split(valid_test.df, SplitRatio = 0.6)
valid.df <- subset(valid_test.df, split2 == TRUE)
test.df <- subset(valid_test.df, split2 == FALSE)

# Print the sizes of the training, validation, and test sets
print(paste("The size of the training set is:", nrow(train_valid.df)))
print(paste("The size of the Validation set is:", nrow(valid.df)))
print(paste("The size of the Test set is:", nrow(test.df)))

# Normalize the data
norm.values <- preProcess(train_valid.df[, -10], method = c("center", "scale"))
train_valid.norm.df <- predict(norm.values, train_valid.df[, -10])
valid.norm.df <- predict(norm.values, valid.df[, -10])
test.norm.df <- predict(norm.values, test.df[, -10])

# Define the best k value
best_k <- 3

# Train the k-NN model with the best k using the training set
best_knn_train <- class::knn(train = train_valid.norm.df,
                              test = train_valid.norm.df,
                              cl = train_valid.df$Personal.Loan,
                              k = best_k)

# Create the confusion matrix for the training set
confusion_matrix_train <- confusionMatrix(best_knn_train, as.factor(train_valid.df$Personal.Loan))

# Train the k-NN model with the best k using the validation set
best_knn_valid <- class::knn(train = train_valid.norm.df,
                              test = valid.norm.df,
                              cl = train_valid.df$Personal.Loan,
                              k = best_k)

# Create the confusion matrix for the validation set
confusion_matrix_valid <- confusionMatrix(best_knn_valid, as.factor(valid.df$Personal.Loan))

# Train the k-NN model with the best k using the test set
best_knn_test <- class::knn(train = train_valid.norm.df,
                             test = test.norm.df,
                             cl = train_valid.df$Personal.Loan,
                             k = best_k)

# Create the confusion matrix for the test set
confusion_matrix_test <- confusionMatrix(best_knn_test, as.factor(test.df$Personal.Loan))

# Display the confusion matrices and their differences
print("Confusion Matrix for Training Set:")
print(confusion_matrix_train)

print("Confusion Matrix for Validation Set:")
print(confusion_matrix_valid)

print("Confusion Matrix for Test Set:")
print(confusion_matrix_test)
```
# The model performs exceptionally well on the training set, with high accuracy and sensitivity.
# The model performs well on the validation set, with high sensitivity, although specificity has decreased compared to the training set. The model still maintains good accuracy and precision.
# The model performs well on the test set, with high sensitivity and accuracy. However, specificity has further decreased compared to both the training and validation sets.

# The high sensitivity suggests that the model is good at identifying customers who are likely to accept a personal loan, which is valuable for marketing purposes. 
# The model shows a trend of decreasing specificity as it moves from the training set to the test set. This means that while the model is very good at correctly identifying customers who would not accept a personal loan (high sensitivity), it tends to produce more false positives in the test set, resulting in a lower specificity.
